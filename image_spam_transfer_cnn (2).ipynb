{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0SBcxcGtjwf"
      },
      "source": [
        "# Transfer learning **VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpjVLT6GbkGP",
        "outputId": "f570f8c3-1403-456d-c3f3-0d3d77fa60ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install split-folders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjgnzWExmSi2",
        "outputId": "422a849a-854b-445e-a67b-36e854f35928"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 1751 files [00:31, 55.81 files/s] \n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "\n",
        "# dataset path\n",
        "input_folder = '/content/drive/MyDrive/SPAM IMAGE dataset/'\n",
        "\n",
        "# Split with a ratio. To only split into training & validation set, set a tuple 'ratio', i.e,\n",
        "# Train(70%), Val(20), Test(10)\n",
        "splitfolders.ratio(input_folder, output='/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2',\n",
        "                   seed=42, ratio=(.7,.2,.1),\n",
        "                   group_prefix=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "506pRza6ZxCH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LsWm6viZ0Vm"
      },
      "outputs": [],
      "source": [
        "# Define your dataset directory paths\n",
        "train_dir = '/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2/train'\n",
        "validation_dir = '/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2//val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma34Df9pZ3_3"
      },
      "outputs": [],
      "source": [
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "# img_size = (224, 224) defines the size to which the input image is resized. Many pre-trained models (like VGG, ResNet, etc.) expect images of this size. These dimensions are widely used in various pre-trained models due to their effectiveness in capturing features while balancing computational cost. It's not necessary to define it explicitly in the provided code, as the preprocess_image function in the code already resizes the image to (224, 224).\n",
        "\n",
        "# batch_size = 32 determines the number of samples/images propagated through the network at once. It affects the speed and performance of the training process. However, in the provided code (for image prediction in Flask), batch size isn't used explicitly since the prediction is performed on single images uploaded via the Flask app, not in a batched manner during training or inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtKMzJ0NZ5R9"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj29JqW5aA_2",
        "outputId": "bc314afe-4940-4e05-ee19-c29b5cd9afad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1225 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMhfd8DFb3yn",
        "outputId": "e69b182b-2b55-4a0f-ab68-9be7a00ad75d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 349 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ch_-rfXb62e",
        "outputId": "112de275-07c1-4363-f525-553ab21265b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained VGG16 model without the top classification layer\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3ocMVO_b6yO"
      },
      "outputs": [],
      "source": [
        "# Add new classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb17bKyicEMc"
      },
      "outputs": [],
      "source": [
        "# Combine base model with new classification layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL-QB_R1cFYt"
      },
      "outputs": [],
      "source": [
        "# Freeze layers of the pre-trained model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spTV93CecHcW",
        "outputId": "a4ee97b5-6bb3-4c2b-8667-01f462cb36f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2HQZpjfcgAl",
        "outputId": "f16eb6f6-5369-4ee6-820d-bd28a030ce3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "38/38 [==============================] - 286s 7s/step - loss: 0.1984 - accuracy: 0.9690 - val_loss: 0.0743 - val_accuracy: 0.9750\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 22s 579ms/step - loss: 0.0717 - accuracy: 0.9824 - val_loss: 0.0577 - val_accuracy: 0.9875\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 23s 589ms/step - loss: 0.0680 - accuracy: 0.9832 - val_loss: 0.0503 - val_accuracy: 0.9875\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 21s 565ms/step - loss: 0.0638 - accuracy: 0.9832 - val_loss: 0.0472 - val_accuracy: 0.9875\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 21s 562ms/step - loss: 0.0589 - accuracy: 0.9858 - val_loss: 0.0624 - val_accuracy: 0.9812\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 21s 562ms/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.0465 - val_accuracy: 0.9875\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 22s 567ms/step - loss: 0.0502 - accuracy: 0.9860 - val_loss: 0.0469 - val_accuracy: 0.9875\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 21s 566ms/step - loss: 0.0391 - accuracy: 0.9883 - val_loss: 0.0472 - val_accuracy: 0.9906\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 22s 592ms/step - loss: 0.0385 - accuracy: 0.9908 - val_loss: 0.0452 - val_accuracy: 0.9937\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 21s 562ms/step - loss: 0.0358 - accuracy: 0.9891 - val_loss: 0.0438 - val_accuracy: 0.9906\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi51L5Pzb6vM",
        "outputId": "63c92549-851b-41dd-94b2-e1491dd5c94e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "model.save('spam_image_filter_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1h7iu3ib6sM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBnJaVB3b6pV"
      },
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('spam_image_filter_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzEYp7xOHfwI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3AZ_fu7coLn"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess uploaded image\n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH-utaLaW_LE",
        "outputId": "9ab407c5-8ede-41ce-a469-3b1b8d35ed91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "The uploaded image is predicted as NOT SPAM.\n"
          ]
        }
      ],
      "source": [
        "# Function to predict whether the image contains spam or not\n",
        "def predict_spam(image_path):\n",
        "    processed_img = preprocess_image(image_path)\n",
        "    prediction = model.predict(processed_img)\n",
        "    return prediction[0][0]  # Return the prediction value (probability)\n",
        "\n",
        "# Provide the path to the uploaded image for prediction\n",
        "uploaded_image_path = '/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2/test/NaturalImages/zzz_00806_9b3d519e0c_m.jpg'\n",
        "\n",
        "# Predict whether the uploaded image contains spam\n",
        "prediction_result = predict_spam(uploaded_image_path)\n",
        "\n",
        "# Threshold for considering if it's spam or not (adjust as needed)\n",
        "spam_threshold = 0.5\n",
        "\n",
        "if prediction_result >= spam_threshold:\n",
        "    print(\"The uploaded image is predicted as SPAM.\")\n",
        "else:\n",
        "    print(\"The uploaded image is predicted as NOT SPAM.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PxnehekW_H0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL-eQovttcJS"
      },
      "source": [
        "# **Resnet50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFlYFwJRXPBl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH7PQAQpt400"
      },
      "outputs": [],
      "source": [
        "# Define your dataset directory paths\n",
        "train_dir = '/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2/train'\n",
        "validation_dir = '/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2//val'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6wZEcpkXO-t"
      },
      "outputs": [],
      "source": [
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L9DTJzSXO5N"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TLgZA7FXO2U",
        "outputId": "79ce3159-2aca-4c58-a6f6-a458e7a325b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1225 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Uerql8DXOzV",
        "outputId": "ca43166a-32ae-4061-9ace-12213e48bfb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 349 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-FgJ0z9XOwc"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained VGG16 model without the top classification layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srzHf6BWXOsl"
      },
      "outputs": [],
      "source": [
        "# Add new classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LkT0VhHwDlL"
      },
      "outputs": [],
      "source": [
        "# Combine base model with new classification layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rmyem0f5wDh6"
      },
      "outputs": [],
      "source": [
        "# Freeze layers of the pre-trained model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw8t7ojywDeZ",
        "outputId": "135b0ae7-b449-4847-ee28-bae63bd47023"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGWIJ4nowDa7",
        "outputId": "096435c1-01cd-414a-e617-2739390b79e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "38/38 [==============================] - 34s 704ms/step - loss: 0.5740 - accuracy: 0.7083 - val_loss: 0.4386 - val_accuracy: 0.8156\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 23s 612ms/step - loss: 0.3832 - accuracy: 0.8961 - val_loss: 0.3108 - val_accuracy: 0.9187\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 24s 637ms/step - loss: 0.2883 - accuracy: 0.9204 - val_loss: 0.2648 - val_accuracy: 0.9344\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 24s 639ms/step - loss: 0.2583 - accuracy: 0.9321 - val_loss: 0.2498 - val_accuracy: 0.9281\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 24s 629ms/step - loss: 0.2269 - accuracy: 0.9472 - val_loss: 0.2362 - val_accuracy: 0.9375\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 24s 629ms/step - loss: 0.2155 - accuracy: 0.9430 - val_loss: 0.2023 - val_accuracy: 0.9438\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 26s 676ms/step - loss: 0.2113 - accuracy: 0.9313 - val_loss: 0.2614 - val_accuracy: 0.8875\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 26s 687ms/step - loss: 0.1829 - accuracy: 0.9505 - val_loss: 0.2385 - val_accuracy: 0.9062\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 23s 600ms/step - loss: 0.1853 - accuracy: 0.9447 - val_loss: 0.2067 - val_accuracy: 0.9312\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 25s 673ms/step - loss: 0.1786 - accuracy: 0.9489 - val_loss: 0.1765 - val_accuracy: 0.9469\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x9y7hB9wDYB"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('spam_image_filter_modelresnet50.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQFBrpKgwjF6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8Wj-mFRwjDI",
        "outputId": "0873a23e-4bfa-4252-f132-817c39b3d18a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcdedf7e680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "The uploaded image is predicted as NOT SPAM.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('spam_image_filter_modelresnet50.h5')\n",
        "\n",
        "# Function to preprocess uploaded image\n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Function to predict whether the image contains spam or not\n",
        "def predict_spam(image_path):\n",
        "    processed_img = preprocess_image(image_path)\n",
        "    prediction = model.predict(processed_img)\n",
        "    return prediction[0][0]  # Return the prediction value (probability)\n",
        "\n",
        "# Provide the path to the uploaded image for prediction\n",
        "uploaded_image_path = '/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2/val/NaturalImages/zzz_00243_a8054e0b34_m.jpg'\n",
        "\n",
        "# Predict whether the uploaded image contains spam\n",
        "prediction_result = predict_spam(uploaded_image_path)\n",
        "\n",
        "# Threshold for considering if it's spam or not (adjust as needed)\n",
        "spam_threshold = 0.5\n",
        "\n",
        "if prediction_result >= spam_threshold:\n",
        "    print(\"The uploaded image is predicted as SPAM.\")\n",
        "else:\n",
        "    print(\"The uploaded image is predicted as NOT SPAM.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjwwB8EcwjAZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-wLuK-9wi9y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUr9fqGLwi65"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s12tc26jwi3x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PXhaEbSwi0y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
