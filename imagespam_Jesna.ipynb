{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders\n"
      ],
      "metadata": {
        "id": "PfN2vTmkDo37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import splitfolders\n",
        "\n",
        "# dataset path\n",
        "input_folder = '/content/drive/MyDrive/SPAM IMAGE dataset/'\n",
        "\n",
        "# Split with a ratio. To only split into training & validation set, set a tuple 'ratio', i.e,\n",
        "# Train(70%), Val(20), Test(10)\n",
        "splitfolders.ratio(input_folder, output='/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2',\n",
        "                   seed=42, ratio=(.7,.2,.1),\n",
        "                   group_prefix=None)"
      ],
      "metadata": {
        "id": "UOD_x9MwDinu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3v7kUjhDimR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "egJW8GC35ljv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "O21tsxuI5q7a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1ej2hI15TpZ",
        "outputId": "d62ee35d-7a48-4556-fa5b-0cd04605698b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1225 images belonging to 2 classes.\n",
            "Found 349 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def create_model(base_model, img_size=(224, 224), num_classes=1):\n",
        "    # Add new classification layers\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    # Combine base model with new classification layers\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze layers of the pre-trained model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define a function to train the model\n",
        "def train_model(model, train_generator, validation_generator, epochs=10):\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples // batch_size\n",
        "    )\n",
        "    return history\n",
        "\n",
        "# Function to load a saved model\n",
        "def load_saved_model(model_path):\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Define your dataset directory paths\n",
        "train_dir = '/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2/train'\n",
        "validation_dir = '/content/drive/MyDrive/SPAM IMAGE dataset/SPAM IMAGE dataset2/val'\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19, ResNet50, InceptionV3, MobileNetV2, DenseNet121\n",
        "\n",
        "# Choose the base model\n",
        "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model_inceptionv3 = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model_mobilenetv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model_densenet50 = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Create models using the function for different base models\n",
        "model_vgg16 = create_model(base_model_vgg16)\n",
        "model_vgg19 = create_model(base_model_vgg19)\n",
        "model_resnet50 = create_model(base_model_resnet50)\n",
        "model_inceptionv3 = create_model(base_model_inceptionv3)\n",
        "model_mobilenetv2 = create_model(base_model_mobilenetv2)\n",
        "model_densenet50 = create_model(base_model_densenet50)\n",
        "\n",
        "# Train the models\n",
        "history_vgg16 = train_model(model_vgg16, train_generator, validation_generator)\n",
        "history_vgg19 = train_model(model_vgg19, train_generator, validation_generator)\n",
        "history_resnet50 = train_model(model_resnet50, train_generator, validation_generator)\n",
        "history_inceptionv3 = train_model(model_inceptionv3, train_generator, validation_generator)\n",
        "history_mobilenetv2 = train_model(model_mobilenetv2, train_generator, validation_generator)\n",
        "history_densenet50 = train_model(model_densenet50, train_generator, validation_generator)\n",
        "\n",
        "# Save the models\n",
        "model_vgg16.save('spam_image_filter_model_vgg16.h5')\n",
        "model_vgg19.save('spam_image_filter_model_vgg19.h5')\n",
        "model_resnet50.save('spam_image_filter_model_resnet50.h5')\n",
        "model_inceptionv3.save('spam_image_filter_model_inceptionv3.h5')\n",
        "model_mobilenetv2.save('spam_image_filter_model_mobilenetv2.h5')\n",
        "model_densenet50.save('spam_image_filter_model_densenet50.h5')\n"
      ],
      "metadata": {
        "id": "AMkXQT_R_r_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('spam_image_filter_model.h5')\n",
        "\n",
        "\n",
        "\n",
        "# Function to preprocess uploaded image\n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Function to predict whether the image contains spam or not\n",
        "\n",
        "def predict_spam(image_path):\n",
        "    processed_img = preprocess_image(image_path)\n",
        "    prediction = model.predict(processed_img)\n",
        "    return prediction[0][0]  # Return the prediction value (probability)\n",
        "\n",
        "# Provide the path to the uploaded image for prediction\n",
        "uploaded_image_path = '/content/drive/MyDrive/SPAM IMAGE dataset/SpamImages/05D89BDjGS.jpg'\n",
        "\n",
        "# Predict whether the uploaded image contains spam\n",
        "prediction_result = predict_spam(uploaded_image_path)\n",
        "\n",
        "# Threshold for considering if it's spam or not (adjust as needed)\n",
        "spam_threshold = 0.5\n",
        "\n",
        "if prediction_result >= spam_threshold:\n",
        "    print(\"The uploaded image is predicted as SPAM.\")\n",
        "else:\n",
        "    print(\"The uploaded image is predicted as NOT SPAM.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "uiqjEE9iDg9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_lFvLStEEz8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict individual data using all models"
      ],
      "metadata": {
        "id": "6Q1df_hWE0lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.preprocessing import image\n",
        "# import numpy as np\n",
        "\n",
        "# # Load the trained model based on the model name\n",
        "# def load_saved_model(model_name):\n",
        "#     model_path = f'spam_image_filter_model_{model_name}.h5'\n",
        "#     return tf.keras.models.load_model(model_path)\n",
        "\n",
        "# # Function to preprocess uploaded image\n",
        "# def preprocess_image(image_path):\n",
        "#     img = image.load_img(image_path, target_size=(224, 224))\n",
        "#     img_array = image.img_to_array(img)\n",
        "#     img_array = np.expand_dims(img_array, axis=0)\n",
        "#     return img_array\n",
        "\n",
        "# # Function to predict whether the image contains spam or not\n",
        "# def predict_spam(model, image_path):\n",
        "#     processed_img = preprocess_image(image_path)\n",
        "#     prediction = model.predict(processed_img)\n",
        "#     return prediction[0][0]  # Return the prediction value (probability)\n",
        "\n",
        "# # Provide the path to the uploaded image for prediction\n",
        "# uploaded_image_path = '/content/drive/MyDrive/SPAM IMAGE dataset/SpamImages/05D89BDjGS.jpg'\n",
        "\n",
        "# # List of model names\n",
        "# model_names = ['vgg16', 'vgg19', 'resnet50', 'inceptionv3', 'mobilenetv2', 'densenet50']\n",
        "\n",
        "# # Iterate through models and perform predictions\n",
        "# for model_name in model_names:\n",
        "#     # Load the model\n",
        "#     model = load_saved_model(model_name)\n",
        "\n",
        "#     # Predict whether the uploaded image contains spam\n",
        "#     prediction_result = predict_spam(model, uploaded_image_path)\n",
        "\n",
        "#     # Threshold for considering if it's spam or not (adjust as needed)\n",
        "#     spam_threshold = 0.5\n",
        "\n",
        "#     # Print prediction result for each model\n",
        "#     if prediction_result >= spam_threshold:\n",
        "#         print(f\"The uploaded image using {model_name.upper()} model is predicted as SPAM.\")\n",
        "#     else:\n",
        "#         print(f\"The uploaded image using {model_name.upper()} model is predicted as NOT SPAM.\")\n"
      ],
      "metadata": {
        "id": "GkM_5OplEznD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}